### 1. 音视频处理基础知识
#### 1.1 音视频编码和解码的基本原理
**编码**是将音视频信号转换成数字格式的过程，这样可以更高效地存储和传输。编码过程包括以下步骤：

- **采样**：将连续的音频信号转换为离散的数字信号。
- **量化**：将采样得到的信号值转换为有限个离散值。
- **压缩**：使用算法（如H.264、AAC）去除冗余数据，减少数据量。

**解码**是编码的逆过程，将编码后的数字信号转换回原始的音视频信号：

- **解压缩**：使用相应的解码算法将压缩数据恢复为近似的原始信号。
- **反量化**：将量化后的信号值还原成连续值。
- **重建**：恢复音视频的原始形式，供播放使用。
#### 1.2 常见的音视频格式及其特点

- **MP4 (MPEG-4 Part 14)**：常用的多媒体容器格式，支持视频、音频、字幕等多种流。视频通常使用H.264编码，音频使用AAC编码。特点是广泛兼容，压缩效率高。
- **AVI (Audio Video Interleave)**：一种早期的多媒体容器格式，支持视频和音频流。特点是格式简单，但相较于现代格式（如MP4）文件较大，不支持高效的压缩。
- **H.264 (Advanced Video Coding, AVC)**：一种视频编码标准，具有高效的压缩性能，广泛用于视频流、蓝光光盘等。特点是较高的压缩效率和图像质量。
- **AAC (Advanced Audio Coding)**：一种音频编码标准，相比MP3具有更高的音质和压缩效率。常用于视频文件和流媒体应用。
#### 1.3 帧率、比特率和分辨率的定义及其对视频质量的影响

- **帧率 (Frame Rate)**：每秒显示的图像帧数，常用单位是FPS（frames per second）。帧率越高，视频越流畅，但数据量也会增加。
- **比特率 (Bitrate)**：每秒传输的数据量，通常以kbps（千比特每秒）或Mbps（兆比特每秒）表示。比特率越高，视频质量越高，但文件大小也会增加。
- **分辨率 (Resolution)**：视频图像的清晰度，表示为宽度 x 高度（例如 1920x1080）。分辨率越高，图像越清晰，但同样会增加文件的大小和处理需求。
### 2. 音视频传输协议
#### 2.1 RTP、RTSP、RTMP 和 WebRTC 的区别及其应用场景

- **RTP (Real-time Transport Protocol)**：用于传输音视频流的协议，提供数据包的时间戳和序列号，支持实时传输。通常与RTCP（Real-time Transport Control Protocol）配合使用来提供质量反馈。应用场景包括视频会议和流媒体传输。
- **RTSP (Real-time Streaming Protocol)**：用于控制流媒体服务器的协议，支持流的播放、暂停和停止。常用于与RTP配合使用，控制视频流的播放。应用场景包括视频点播和实时流控制。
- **RTMP (Real-time Messaging Protocol)**：由Adobe开发的协议，主要用于实时流媒体传输，具有低延迟和高效的传输能力。通常用于直播和流媒体应用。
- **WebRTC (Web Real-Time Communication)**：一个用于网页浏览器的实时通信协议，支持音视频和数据流的实时传输，内置NAT穿透功能。应用场景包括视频通话、实时协作和在线游戏。
#### 2.2 如何处理网络延迟和丢包问题来提高音视频传输的稳定性和质量？

- **延迟处理**：
   - **缓冲区**：在接收端使用缓冲区来存储一定量的数据，平滑播放过程，减少由于网络波动引起的延迟。
   - **自适应比特率**：根据网络带宽动态调整视频流的比特率，减少因带宽不足导致的延迟。
- **丢包处理**：
   - **FEC (Forward Error Correction)**：在数据流中添加冗余信息，以便在丢包时进行数据恢复。
   - **重传机制**：在协议层面实现数据包重传，尤其是在丢包率较高的环境下。
   - **丢包隐藏**：使用视频编码技术隐藏丢失的数据包，如插值和预测技术，尽量减少用户感知到的质量损失。

这些解答可以帮助你在面试中清晰地展示你对音视频处理的理解和相关技术的应用。

### H.264（Advanced Video Coding, AVC）概述
**H.264**，也被称为**Advanced Video Coding (AVC)**，是一种视频压缩标准，由国际电信联盟（ITU）和国际标准化组织（ISO/IEC）联合制定。它是现代视频编码标准中的一种，被广泛应用于各种视频传输和存储场景中。
#### 1. H.264的基本原理
H.264的视频编码过程包括以下几个主要步骤：

1. **分块（Partitioning）**：
   - 视频帧被划分为多个宏块（Macroblocks），每个宏块通常是16x16像素。在编码时，宏块可以进一步划分为更小的块，如4x4或8x8像素，增强编码效率。
2. **运动估计（Motion Estimation）**：
   - 通过比较当前帧和参考帧的宏块，估计图像中的运动信息。运动估计可以找到最接近的参考区域，从而减少需要编码的数据量。
3. **运动补偿（Motion Compensation）**：
   - 基于运动估计结果，对当前帧进行运动补偿，减小与参考帧的差异。这种差异称为预测残差（Residual），需要进一步编码。
4. **预测编码（Prediction Coding）**：
   - 对宏块进行预测，使用预测模型（如帧内预测和帧间预测）来估计当前宏块的像素值。预测的结果与实际值之间的差异被编码。
5. **变换和量化（Transform and Quantization）**：
   - 对预测残差进行离散余弦变换（DCT），将其转换为频域信号。随后，通过量化过程压缩频域信号，从而减少数据量。
6. **熵编码（Entropy Coding）**：
   - 使用熵编码算法（如CABAC或CAVLC）对量化后的数据进行编码，进一步压缩数据。
7. **帧内/帧间预测**：
   - **帧内预测**：在同一帧内使用周围像素预测当前像素的值，适用于静态区域或高纹理区域。
   - **帧间预测**：使用前面的帧进行预测，适用于动态场景，通过运动补偿减少数据量。
#### 2. H.264的特点

- **高压缩效率**：H.264相比于早期的视频编码标准（如MPEG-2），具有更高的压缩比，能够在相同的比特率下提供更高的视频质量。
- **灵活的编码选项**：支持多种预测模式、变换尺寸和量化方式，使得编码器可以根据不同的场景优化编码策略。
- **错误恢复能力**：H.264提供了多种机制来处理丢包和传输错误，增加了其在不可靠网络环境中的适用性。
- **应用广泛**：H.264被广泛应用于流媒体、视频会议、蓝光光盘、网络视频等多个领域。
#### 3. H.264的应用场景

- **流媒体**：用于网络视频流媒体传输，提供高质量的视频体验。
- **视频会议**：在视频会议系统中使用H.264编码以提高传输效率和视频质量。
- **蓝光光盘**：作为高清晰度光盘的标准编码格式，提供优质的视频播放体验。
- **广播**：用于数字电视广播和卫星电视等领域，提供高质量的视频内容。

通过了解H.264的基本原理、特点和应用场景，你可以在面试中有效地展示你对这一视频编码标准的理解。

# hr沟通 8.22
# 一面-技术 8.23

1. hr 介绍流程：自我介绍，面试官提问，反问。技术面试，由技术经理和技术总监来面
2. 自我介绍
3. 中台系统
   1. 简单说一下你们微服务用了哪些框架，技术点，简单的描述一下
   2. 用的 gin吗，有没有用其他的框架，比如说 go-zero
   3. 说一下各个服务之间的相互的调用的逻辑是怎么调用的
   4. 项目上线了是吧，管理哪些东西？
   5. 这些工具都是在你们公司内部用的是吧？
   6. 并发量是多少？微服务系统1 千的 qps 吗？
   7. 当初选这个微服务是什么原因呢？是想分成不同的模块是吧 
   8. 2022 年你进来的时候就已经有框架了，还是你从0 到 1跟着走的
   9. 比如现在来到我们公司，让你基于 gin 搭一个类似的微服务中台系统（有流媒体相关的，有设备接入的，也有用户管理的），让你去做的话，先搭一个框架，你感觉多长时间能搭完（基于你们现在这个 gin 框架的延伸的话，你能搭起来  ）
   10. 可能也看过一些其他的微服务框架，包括字节的 cloudweme，go-zero，这些开源的微服务框架，相比于这些框架来说，有这些现成的你们不用，你觉得你们自己搭建的微服务框架有什么优点或者缺点呀
   11. 代码隔离这一方面你们是怎么做的？
   12. 比如一个用户服务，一个广告服务，用户服务要去调广告服务，是怎么调的？用户服务是一个库，这个库是 GitHub 这种方式把库给你，你能看到相关的源码，源码保护这一块。
4. 介绍一下游戏服务器开发这一块
   1. 这个已经上线了吗？
5. 公司这块的问题，是经营出现了问题了吗？
6. 未来找工作的打算
7. go 写一下嵌入式的设备
8. 聊他们公司的业务和项目，音视频相关的

# 二面-综合 8.27
